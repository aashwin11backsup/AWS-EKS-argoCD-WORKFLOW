name: '2-Deploy Apps to EKS'

on:
  workflow_dispatch:
    inputs:
      aws_region:
        description: 'AWS Region (e.g., us-east-1)'
        required: true
        default: 'us-east-1'
      cluster_name:
        description: 'EKS Cluster Name (e.g., staging-eks-demo)'
        required: true
        default: 'staging-eks-demo'

jobs:
  deploy-to-eks:
    name: 'Deploy ALB Controller and ArgoCD'
    runs-on: ubuntu-latest

    permissions:
      id-token: write
      contents: read

    steps:
      - name: Checkout Code
        uses: actions/checkout@v4

      - name: Configure AWS Credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ${{ github.event.inputs.aws_region }}

      # Step to install eksctl, a required tool
      - name: Install eksctl
        run: |
          curl --silent --location "https://github.com/weaveworks/eksctl/releases/latest/download/eksctl_$(uname -s)_amd64.tar.gz" | tar xz -C /tmp
          sudo mv /tmp/eksctl /usr/local/bin
          echo "eksctl version: $(eksctl version)"
          
#-------------------------------------------------------------------------------------------------------------------------------
      # 1. Connect to the EKS Cluster
      - name: Update Kubeconfig
        run: |
          aws eks update-kubeconfig --region ${{ github.event.inputs.aws_region }} --name ${{ github.event.inputs.cluster_name }}
          echo "Kubeconfig updated for cluster: ${{ github.event.inputs.cluster_name }}"
          sleep 5
          echo "-----> Checking nodes:"
          kubectl get nodes
          sleep 5
#-------------------------------------------------------------------------------------------------------------------------------

#-------------------------------------------------------------------------------------------------------------------------------
      # 2. Create IAM Role and Service Account for ALB Controller (IRSA)
      # This is the CORRECTED step. It replaces the old logic of attaching policies to the node role.
      - name: Create IAM Service Account for ALB Controller
        run: |
          eksctl create iamserviceaccount \
            --cluster=${{ github.event.inputs.cluster_name }} \
            --namespace=kube-system \
            --name=aws-load-balancer-controller \
            --role-name "AmazonEKSLoadBalancerControllerRole-${{ github.event.inputs.cluster_name }}" \
            --attach-policy-arn=arn:aws:iam::aws:policy/AWSLoadBalancerControllerIAMPolicy \
            --approve \
            --region=${{ github.event.inputs.aws_region }}
          echo "IAM Role and Service Account for ALB Controller created."
          sleep 5
#-------------------------------------------------------------------------------------------------------------------------------

#-------------------------------------------------------------------------------------------------------------------------------
      # 3. Install AWS Load Balancer Controller
      - name: Install AWS Load Balancer Controller
        run: |
          helm repo add eks https://aws.github.io/eks-charts
          helm repo update
          
          # This command now works correctly because the Service Account 'aws-load-balancer-controller'
          # has been created by eksctl and is annotated with the correct IAM role.
          helm upgrade --install aws-load-balancer-controller eks/aws-load-balancer-controller \
            --namespace kube-system \
            --set clusterName=${{ github.event.inputs.cluster_name }} \
            --set serviceAccount.create=false \
            --set serviceAccount.name=aws-load-balancer-controller \
            --set region=${{ github.event.inputs.aws_region }}

          echo "----------WAITING FOR 60 SECONDS FOR THE ALB CONTROLLER TO DEPLOY----------"
          sleep 60
          echo "---> Checking ALB Controller deployment status:"
          kubectl get deployment aws-load-balancer-controller -n kube-system
          sleep 5
#-------------------------------------------------------------------------------------------------------------------------------

#-------------------------------------------------------------------------------------------------------------------------------
      # 4. Install ArgoCD
      - name: Install ArgoCD
        run: |
          helm repo add argo https://argoproj.github.io/argo-helm
          helm repo update
          helm upgrade --install argocd argo/argo-cd \
            --namespace argocd \
            --create-namespace \
            --set server.service.type=ClusterIP \
            --set server.extraArgs={--insecure}
          
          echo "----------WAITING FOR 30 SECONDS FOR ARGO PODS TO RUN----------"
          sleep 30
          echo "---> Checking argocd pods:"
          kubectl get pods -n argocd
          sleep 5
#-------------------------------------------------------------------------------------------------------------------------------

#-------------------------------------------------------------------------------------------------------------------------------
      # 5. Expose ArgoCD Server using Ingress
      - name: Expose ArgoCD Server
        run: |
          kubectl wait --for=condition=ready pod -l app.kubernetes.io/name=argocd-server -n argocd --timeout=300s
          # Assuming you have an Ingress manifest in an 'argocd/' directory
          kubectl apply -f argocd/
          sleep 5
#-------------------------------------------------------------------------------------------------------------------------------

#-------------------------------------------------------------------------------------------------------------------------------
      # 6. Get the ALB DNS Name for ArgoCD
      - name: Get Ingress URL
        run: |
          echo "---------Waiting up to 2 minutes for Ingress to get an address...------"
          # This command waits until the hostname is populated or times out after 120 seconds
          kubectl wait --for=jsonpath='{.status.loadBalancer.ingress[0].hostname}' ingress/shared-main-ingress -n argocd --timeout=120s

          echo "=========================================================================="
          echo "âœ… Your ArgoCD URL is:"
          kubectl get ingress shared-main-ingress -n argocd -o jsonpath='{.status.loadBalancer.ingress[0].hostname}'
          echo ""
          echo "=========================================================================="

          echo "ðŸ”‘ ArgoCD initial admin password:"
          kubectl -n argocd get secret argocd-initial-admin-secret -o jsonpath="{.data.password}" | base64 -d
          echo ""
#-------------------------------------------------------------------------------------------------------------------------------